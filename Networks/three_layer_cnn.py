# -*- coding: utf-8 -*-
"""DT2112_process_one_wav.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LTzC7Pun5OMbV4RBHxkWnKj1hZPYQULD
"""
import os
import scipy.io.wavfile as wav
import librosa
import soundfile
import pathlib
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D
import numpy as np
from tensorflow.keras import layers, utils, Model
import tensorflow.keras
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input, Add, Activation, Flatten, Dropout
from tensorflow.keras.layers import Conv2D, ZeroPadding2D, AveragePooling2D
from tensorflow.keras.layers import BatchNormalization, Reshape
from tensorflow.keras.regularizers import l2
from tensorflow.keras import backend as K
from keras.datasets import mnist
from keras.utils import to_categorical
from keras.losses import categorical_crossentropy
from keras.optimizers import rmsprop
import cv2

#os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"



# Creates a ndarray filter mask from a time series.
# sr, x is what is returned from wav.read(filename.wav)
# sr: sampling rate (int), x: time series (nd.array)

def mask_from_timeseries(sr, x):
    x = x.astype('float16')
    S, ph = librosa.magphase(librosa.stft(x))
    # i'm not sure what the value of "time" should be. 0.1 works well for segment lengths of 0.5 seconds.
    time = 0.1
    S_filter = librosa.decompose.nn_filter(S,
                                           aggregate=np.median,
                                           metric='cosine',
                                           width=int(librosa.time_to_frames(time, sr=sr)))
    S_filter = np.minimum(S, S_filter)
    margin = 5
    power = 2
    mask = librosa.util.softmask(S - S_filter,
                                 margin * S_filter,
                                 power=power)
    return mask

# diretory is the directory where all the samples is located
def getMasks(directory):
    masks = []
    for file in os.listdir(directory):
        filename = os.fsdecode(file)
        if filename.endswith(".wav"):
            # print(filename)
            sr, x = wav.read(directory + "/" + filename)
            masks.append(mask_from_timeseries(sr, x))
        else:
            continue
    return masks

# diretory is the directory where all the samples is located
def getSpectogram(directory):
    spect = []
    for file in os.listdir(directory):
        filename = os.fsdecode(file)
        if filename.endswith(".wav"):
            sr, x = wav.read(directory + "/" + filename)
            x = x.astype('float16')
            S, ph = librosa.magphase(librosa.stft(x))
            spect.append(S)
        else:
            continue
    return spect

print ("Loading data....")
y1Apath = "../Originals/y1_A_clean"
y2Bpath = "../Originals/y2_B_clean"
y1Ay2Apath = "../Originals/y1_A_y2_A_MIX"
y1By2Bpath = "../Originals/y1_B_y2_B_MIX"
# Change path here
masks1 = getMasks(y1Apath)
masks2 = getMasks(y2Bpath)
spectoA = getSpectogram(y1Ay2Apath)
spectoB = getSpectogram(y1By2Bpath)

#tensorflow.compat.v1.disable_eager_execution()

class DNN():

  def __init__(self, kernel_initializer, kernel_regularizer, gamma_initializer,
               dropout, epsilon, weight_decay, momentum):

    self.kernel_regularizer = kernel_regularizer
    self.kernel_initializer = kernel_initializer
    self.gamma_initializer = gamma_initializer
    self.dropout = dropout
    self.epsilon = epsilon
    self.weight_decay = weight_decay
    self.momentum = momentum

  def build_block(self, input, num_filters, kernel, dilation, name, padding_dim1,
                  padding_dim2=None):

    channel_axis = 1 if K.image_data_format() == "channels_first" else -1
    if padding_dim2 != None:
      x = ZeroPadding2D(padding=(padding_dim1, padding_dim2))(input)
    else:
      x = ZeroPadding2D(padding=(padding_dim1))(input)
    x = Conv2D(filters=num_filters, kernel_size=kernel, padding='same',strides=(1, 1),
                    activation='relu', name=name, dilation_rate=dilation)(x)
    x = BatchNormalization(axis=channel_axis, momentum=self.momentum,
                              epsilon=self.epsilon,
                              gamma_initializer=self.gamma_initializer,
                              beta_initializer='zeros')(x)
    return x

  def build_model(self, input_1, input_2):

    channel_axis = 1 if K.image_data_format() == "channels_first" else -1

    # # DNN_1
    # x = self.build_block(input_1, 64, (1, 7), (1, 1), 'conv_1a',(3, 3), (0, 0))
    # x = self.build_block(x, 64, (7, 1), (1, 1), 'conv_2a',(0, 0), (3, 3))
    # x = self.build_block(x, 64, (5, 5), (1, 1), 'conv_3a',2)
    # x = self.build_block(x, 64, (5, 5), (2, 1), 'conv_4a',(2, 2), (4, 4))
    # x = self.build_block(x, 64, (5, 5), (4, 1), 'conv_5a',(2, 2), (8, 8))
    # x = self.build_block(x, 64, (5, 5), (8, 1), 'conv_6a',(2, 2), (16, 16))
    # x = self.build_block(x, 64, (5, 5), (16, 1), 'conv_7a',(2, 2), (32, 32))
    # x = Conv2D(filters=64, kernel_size=(1, 1), padding='same',strides=(1, 1),
    #                 activation='relu', name='conv_8a', dilation_rate=(1, 1))(x)
    # x = AveragePooling2D((8, 8))(x)
    # x = Flatten()(x)

    # if self.dropout > 0.0: x = Dropout(self.dropout)(x)
    # output_1 = Dense(1024,activation='sigmoid',kernel_regularizer=l2(self.weight_decay))(x)

    # output_1 = Reshape((32, 32, 1))(output_1)

    # # DNN_2
    # x = self.build_block(input_2, 64, (1, 7), (1, 1), 'conv_1b',(3, 3), (0, 0))
    # x = self.build_block(x, 64, (7, 1), (1, 1), 'conv_2b',(0, 0), (3, 3))
    # x = self.build_block(x, 64, (5, 5), (1, 1), 'conv_3b',2)
    # x = self.build_block(x, 64, (5, 5), (2, 1), 'conv_4b',(2, 2), (4, 4))
    # x = self.build_block(x, 64, (5, 5), (4, 1), 'conv_5b',(2, 2), (8, 8))
    # x = self.build_block(x, 64, (5, 5), (8, 1), 'conv_6b',(2, 2), (16, 16))
    # x = self.build_block(x, 64, (5, 5), (16, 1), 'conv_7b',(2, 2), (32, 32))
    # x = Conv2D(filters=64, kernel_size=(1, 1), padding='same',strides=(1, 1),
    #                 activation='relu', name='conv_8b', dilation_rate=(1, 1))(x)
    # x = AveragePooling2D((8, 8))(x)
    # x = Flatten()(x)

    # if self.dropout > 0.0: x = Dropout(self.dropout)(x)
    # output_2 = Dense(1024,activation='sigmoid',kernel_regularizer=l2(self.weight_decay))(x)

    # output_2= Reshape((32, 32, 1))(output_2)

    # model = Model(inputs=[input_1, input_2],
    #          outputs=[output_1, output_2])

    # return model
     # DNN_1
    x = self.build_block(input_1, 8, (3, 3), (1, 1), 'conv_1a',(3, 3), (0, 0))
    x = self.build_block(x, 8, (7, 1), (1, 1), 'conv_2a',(0, 0), (3, 3))
    x = self.build_block(x, 8, (5, 5), (1, 1), 'conv_3a',2)
    #x = self.build_block(x, 8, (5, 5), (2, 1), 'conv_4a',(2, 2), (4, 4))
    #x = self.build_block(x, 8, (5, 5), (4, 1), 'conv_5a',(2, 2), (8, 8))
    #x = self.build_block(x, 8, (5, 5), (8, 1), 'conv_6a',(2, 2), (16, 16))
    #x = self.build_block(x, 8, (5, 5), (16, 1), 'conv_7a',(2, 2), (32, 32))
    #x = Conv2D(filters=8, kernel_size=(1, 1), padding='same',strides=(1, 1),
    #                activation='relu', name='conv_8a', dilation_rate=(1, 1))(x)
    x = AveragePooling2D((16, 16))(x)
    x = Flatten()(x)

    #if self.dropout > 0.0: x = Dropout(self.dropout)(x)
    output_1 = Dense(65536,activation='sigmoid',kernel_regularizer=l2(self.weight_decay))(x)

    output_1 = Reshape((1024, 64))(output_1)

    # DNN_2
    x = self.build_block(input_2, 8, (3, 3), (1, 1), 'conv_1b',(3, 3), (0, 0))
    x = self.build_block(x, 8, (7, 1), (1, 1), 'conv_2b',(0, 0), (3, 3))
    x = self.build_block(x, 8, (5, 5), (1, 1), 'conv_3b',2)
    #x = self.build_block(x, 8, (5, 5), (2, 1), 'conv_4b',(2, 2), (4, 4))
    #x = self.build_block(x, 8, (5, 5), (4, 1), 'conv_5b',(2, 2), (8, 8))
    #x = self.build_block(x, 8, (5, 5), (8, 1), 'conv_6b',(2, 2), (16, 16))
    #x = self.build_block(x, 8, (5, 5), (16, 1), 'conv_7b',(2, 2), (32, 32))
    #x = Conv2D(filters=8, kernel_size=(1, 1), padding='same',strides=(1, 1),
    #                activation='relu', name='conv_8b', dilation_rate=(1, 1))(x)
    x = AveragePooling2D((16, 16))(x)
    x = Flatten()(x)

    #if self.dropout > 0.0: x = Dropout(self.dropout)(x)
    output_2 = Dense(65536,activation='sigmoid',kernel_regularizer=l2(self.weight_decay))(x)

    output_2= Reshape((1024, 64))(output_2)

    model = Model(inputs=[input_1, input_2],
             outputs=[output_1, output_2])

    return model


if __name__ == "__main__":
  print("******STARTING BUILDING THE NETWORK******")

  """Create an input, build the model, print the network summary"""
  dnn = DNN('he_normal', 0.0002, 'uniform', 0.7, 1e-5, 0.0005, 0.1)

  ######################################


  img_rows = 64
  img_cols = 1024
  sample_size = len(spectoA)

  # Input 1 and Output 1
  spectoA = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in spectoA]).astype('float16')
  masks1 = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in masks1]).astype('float16')

  spectoA = np.reshape(spectoA, (sample_size, img_cols, img_rows, 1))
  # Input 2 and Output 2
  spectoB = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in spectoB]).astype('float16')
  masks2 = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in masks2]).astype('float16')
  spectoB = np.reshape(spectoB, (sample_size, img_cols, img_rows, 1))

  print (spectoA.shape)
  #print (type(spectoA))
  #print (type(spectoB))
  #print (type(masks1))
  #print (type(masks2))

  input_shape = spectoA.shape[1:]
  #print(input_shape)

  batch_size = 4
  epochs = 8

   # Generate data parameters
  # samples = 10
  # channel = 1
  # dim = 32


  ## Random test data
  # train_data = np.array([[[[np.random.randint(low=0, high=10) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)]).astype('float32')
  # train_data2 = np.array([[[[np.random.randint(low=0, high=10) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)]).astype('float32')
  # test_data = np.array([[[[np.random.randint(low=0, high=2) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)]).astype('float32')
  # print("train_data.shape = ", train_data.shape)
  # # train_data.reshape(dim, dim, channel)
  # print("train_data.shape = ", train_data.shape[1:])
  input1 = Input(shape=spectoA.shape[1:], name='input_1')
  input2 = Input(shape=spectoB.shape[1:], name='input_2')
  dnn = dnn.build_model(input1, input2)

  # Compile our model
  dnn.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['mse'])

  print("STARTING TRAINING !!!! ")
  # # Train our model

  dnn.fit([spectoA, spectoB], [masks1, masks2],
          epochs=epochs,
          validation_split=0.2,
          verbose=1)

  #dnn.fit([train_data, train_data2], [test_data, test_data],
  #         batch_size=batch_size,
  #         epochs=epochs,
  #         validation_split=0.2,
  #         verbose=1)

  # x = tensorflow.cast(train_data, tf.float32)
  # y = dnn.predict(x)
  # print(y.shape)
#   print(y)

#   Print the model summary
  #dnn.summary()
  #utils.plot_model(dnn)

####################################################
print ("Loading data....")
y1ADir = "../Originals/y1_A_clean/rest_data"
y2BDir = "../Originals/y2_B_clean/rest_data"
y1Ay2ADir = "../Originals/y1_A_y2_A_MIX/rest_data"
y1By2BDir = "../Originals/y1_B_y2_B_MIX/rest_data"
testMasks1 = getMasks(y1ADir)
testMasks2 = getMasks(y2BDir)
testSpectoA, phaseA = getSpectogram(y1Ay2ADir)
testSpectoB, phaseB = getSpectogram(y1By2BDir)


####################################################
# Evaluate
print ("Transform data....")
img_rows = 64
img_cols = 1024
sample_size = len(testSpectoA)

# Input 1 and Output 1
testSpectoA = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in testSpectoA]).astype('float16')
testMasks1 = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in testMasks1]).astype('float16')
testSpectoA = np.reshape(testSpectoA, (sample_size, img_cols, img_rows, 1))
#phaseA = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in phaseA])
# Input 2 and Output 2
testSpectoB = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in testSpectoB]).astype('float16')
testMasks2 = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in testMasks2]).astype('float16')
testSpectoB = np.reshape(testSpectoB, (sample_size, img_cols, img_rows, 1))

print ("Evaluating....")
#score1, score2, mse1, mse2 = model.evaluate({'input1': testSpectoA, 'input2': testSpectoB}, {'output1': testMasks1, 'output2': testMasks2})
print (dnn.evaluate({'input1': testSpectoA, 'input2': testSpectoB}, {'output1': testMasks1, 'output2': testMasks2}))
#print ("Score 1: " + score1)
#print ("Score 2: " + score1)
#print ("MSE 1: " + mse1)
#print ("MSE 2: " + mse1)
