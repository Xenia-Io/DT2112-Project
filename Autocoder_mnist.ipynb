{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autocoder_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEsKBMh3iPsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34edcf2c-f731-4f05-92f5-c237b0f73796"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import backend as K\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import rmsprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Process data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Creating model\n",
        "img_shape = (256, 256, 3)\n",
        "batch_size = 3\n",
        "epochs = 5\n",
        "# Generate data parameters\n",
        "samples = 1\n",
        "channel = 3\n",
        "dim = 256\n",
        "\n",
        "train_data = np.array([[[[np.random.randint(low=5, high=20) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)])\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "  encoder = layers.BatchNormalization()(encoder)\n",
        "  encoder = layers.Activation('relu')(encoder)\n",
        "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "  encoder = layers.BatchNormalization()(encoder)\n",
        "  encoder = layers.Activation('relu')(encoder)\n",
        "  return encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "  encoder = conv_block(input_tensor, num_filters)\n",
        "  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\n",
        "  return encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "  #decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  return decoder\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "# 256\n",
        "\n",
        "encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
        "# 128\n",
        "\n",
        "encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
        "# 64\n",
        "\n",
        "encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
        "# 32\n",
        "\n",
        "#encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
        "# 16\n",
        "\n",
        "#encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
        "# 8\n",
        "\n",
        "center = conv_block(encoder2_pool, 256)\n",
        "# center\n",
        "\n",
        "#decoder4 = decoder_block(center, encoder4, 512)\n",
        "# 16\n",
        "\n",
        "#decoder3 = decoder_block(decoder4, encoder3, 256)\n",
        "# 32\n",
        "\n",
        "decoder2 = decoder_block(center, encoder2, 128)\n",
        "# 64\n",
        "\n",
        "decoder1 = decoder_block(decoder2, encoder1, 64)\n",
        "# 128\n",
        "\n",
        "decoder0 = decoder_block(decoder1, encoder0, 32)\n",
        "# 256\n",
        "\n",
        "outputs = layers.Flatten()(decoder0)\n",
        "\n",
        "outputs = layers.Dense(256, activation='sigmoid')(outputs)\n",
        "\n",
        "outputs = layers.Dense(10, activation='softmax')(outputs)\n",
        "\n",
        "model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 3, 3, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 6, 6, 128)         131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 12, 12, 64)        32832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 24, 24, 32)        8224      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               4718848   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 6,459,402\n",
            "Trainable params: 6,456,138\n",
            "Non-trainable params: 3,264\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3021s 50ms/sample - loss: 0.4281 - acc: 0.8730 - val_loss: 0.1345 - val_acc: 0.9741\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3030s 51ms/sample - loss: 0.1449 - acc: 0.9735 - val_loss: 0.1476 - val_acc: 0.9731\n",
            "Epoch 3/5\n",
            "39003/60000 [==================>...........] - ETA: 17:43 - loss: 0.1260 - acc: 0.9784"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}