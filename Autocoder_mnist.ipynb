{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autocoder_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmZsRxiRDepu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9426a300-19b5-4f07-f8fc-9a26d54880da"
      },
      "source": [
        "!unzip Train.zip"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Train.zip\n",
            "replace y1_A_clean/sample11.wav? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace y1_A_clean/sample640.wav? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtygZyS-_I2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0c3f84cc-7ec2-452f-d777-06fec027941a"
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY9ozgnm-YYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, mask1, spec1, mask2, spec2):\n",
        "        self.mask1 = mask1\n",
        "        self.spec1 = spec1\n",
        "        self.mask2 = mask2\n",
        "        self.spec2 = spec2\n",
        "\n",
        "    def __str__(self):\n",
        "        print(f\"mask1: {self.mask1} spec1: {self.spec1} mask2: {self.mask2} spec2: {self.spec1}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCoRvUiF-LCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import scipy.io.wavfile as wav\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile\n",
        "#from pydub import AudioSegment, silence\n",
        "#from pydub.silence import detect_silence\n",
        "#from train_tuples import Trainer\n",
        "import pathlib\n",
        "\n",
        "'''\n",
        "def find_silence(wav1):\n",
        "    myaudio = intro = AudioSegment.from_wav(wav1)\n",
        "\n",
        "    silence = detect_silence(myaudio, min_silence_len=200, silence_thresh=-25)\n",
        "\n",
        "    silence = [((start / 1000), (stop / 1000)) for start, stop in silence]  # convert to sec\n",
        "    print(silence)\n",
        "\n",
        "\n",
        "# Mixes 2 .wav files\n",
        "def mixture2(wav1, wav2, dest):\n",
        "    d, samplerate = soundfile.read(wav1)\n",
        "    soundfile.write(wav1, d, samplerate, subtype='PCM_16')\n",
        "    d, samplerate = soundfile.read(wav2)\n",
        "    soundfile.write(wav2, d, samplerate, subtype='PCM_16')\n",
        "\n",
        "    sound1 = AudioSegment.from_file(wav1)\n",
        "    sound2 = AudioSegment.from_file(wav2)\n",
        "\n",
        "    combined = sound1.overlay(sound2)\n",
        "\n",
        "    combined.export(dest, format='wav')\n",
        "\n",
        "\n",
        "# Make the 2 input .wav files the same length\n",
        "def make_same_length(wav1, wav2):\n",
        "    wav1_len = librosa.get_duration(filename=wav1)\n",
        "    wav2_len = librosa.get_duration(filename=wav2)\n",
        "    if wav1_len < wav2_len:\n",
        "        y, sr = librosa.load(wav2, duration=wav1_len)\n",
        "        librosa.output.write_wav(wav2, y, sr)\n",
        "    else:\n",
        "        y, sr = librosa.load(wav1, duration=wav2_len)\n",
        "        librosa.output.write_wav(wav1, y, sr)\n",
        "    return [wav1, wav2]\n",
        "\n",
        "\n",
        "# Splits the .wav file in split_length in several chunks. Every chunk is split_length seconds\n",
        "def split_wav(wav_file, split_length, target_location):\n",
        "    t1 = 0 * 1000  # Works in milliseconds\n",
        "    t2 = split_length * 1000\n",
        "    newAudio = AudioSegment.from_wav(wav_file)\n",
        "    outfile = \"sample\"\n",
        "    i = 0\n",
        "    for i in range(int(newAudio.duration_seconds / split_length)):\n",
        "        tmp = newAudio[t1:t2]\n",
        "        tmp.export(f\"{target_location}/{outfile}{i}.wav\", format=\"wav\")  # Exports to a wav file in the current path.\n",
        "        t1 += split_length * 1000\n",
        "        t2 += split_length * 1000\n",
        "\n",
        "\n",
        "# Creates a ndarray filter mask from a time series.\n",
        "# sr, x is what is returned from wav.read(filename.wav)\n",
        "# sr: sampling rate (int), x: time series (nd.array)\n",
        "\n",
        "def mask_from_timeseries(sr, x):\n",
        "    x = x.astype('float')\n",
        "    S, ph = librosa.magphase(librosa.stft(x))\n",
        "    # i'm not sure what the value of \"time\" should be. 0.1 works well for segment lengths of 0.5 seconds.\n",
        "    time = 0.1\n",
        "    S_filter = librosa.decompose.nn_filter(S,\n",
        "                                           aggregate=np.median,\n",
        "                                           metric='cosine',\n",
        "                                           width=int(librosa.time_to_frames(time, sr=sr)))\n",
        "    S_filter = np.minimum(S, S_filter)\n",
        "    margin = 5\n",
        "    power = 2\n",
        "    mask = librosa.util.softmask(S - S_filter,\n",
        "                                 margin * S_filter,\n",
        "                                 power=power)\n",
        "    return mask\n",
        "\n",
        "'''\n",
        "# diretory is the directory where all the samples is located\n",
        "def getMasks(directory):\n",
        "    masks = []\n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        if filename.endswith(\".wav\"):\n",
        "            # print(filename)\n",
        "            sr, x = wav.read(directory + \"/\" + filename)\n",
        "            masks.append(mask_from_timeseries(sr, x))\n",
        "        else:\n",
        "            continue\n",
        "    return masks\n",
        "\n",
        "\n",
        "# diretory is the directory where all the samples is located\n",
        "def getSpectogram(directory):\n",
        "    spect = []\n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        if filename.endswith(\".wav\"):\n",
        "            sr, x = wav.read(directory + \"/\" + filename)\n",
        "            x = x.astype('float')\n",
        "            S, ph = librosa.magphase(librosa.stft(x))\n",
        "            spect.append(S)\n",
        "        else:\n",
        "            continue\n",
        "    return spect\n",
        "# Change path here \n",
        "masks1 = getMasks(\"/content/y1_A_clean\")\n",
        "masks2 = getMasks(\"/content/y2_B_clean\")\n",
        "spectoA = getSpectogram(\"/content/y1_A_y2_A_MIX\")\n",
        "spectoB = getSpectogram(\"/content/y1_B_y2_B_MIX\")\n",
        "\n",
        "list_of_object = []\n",
        "for i, j, k, l in zip(masks1, spectoA, masks2, spectoB):\n",
        "    list_of_object.append(Trainer(i, j, k, l))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3elOPnNxnu6",
        "colab_type": "text"
      },
      "source": [
        "This is the Autoencoder network for processing a mixed sound file and separate the voices into two sound files. \n",
        "\n",
        "Next piece of code loads in an example soundfile to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "160cfc76-266f-4534-ce69-4832c872b8b7",
        "id": "ZGW20UhsFwFQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "img_rows = 64\n",
        "img_cols = 1024 \n",
        "sample_size = len(spectoA)\n",
        "\n",
        "# Input 1 and Output 1\n",
        "spectoA = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in spectoA])\n",
        "masks1 = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in masks1])\n",
        "spectoA = np.reshape(spectoA, (sample_size, img_cols, img_rows, 1))\n",
        "# Input 2 and Output 2\n",
        "spectoB = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in spectoB])\n",
        "masks2 = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in masks2])\n",
        "spectoB = np.reshape(spectoB, (sample_size, img_cols, img_rows, 1))\n",
        "\n",
        "print (spectoA.shape)\n",
        "#print (type(spectoA))\n",
        "#print (type(spectoB))\n",
        "#print (type(masks1))\n",
        "#print (type(masks2))\n",
        "\n",
        "input_shape = spectoA.shape[1:]\n",
        "#print(input_shape)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(656, 1024, 64, 1)\n",
            "(1024, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azdgkkYgx6S8",
        "colab_type": "text"
      },
      "source": [
        "Following code creates the model for network. The model is inspired by
        https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb \n",
        "Import all the necessary dependencies to make the model work. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHYTxgBCybgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import rmsprop\n",
        "from keras.layers import LeakyReLU, Dense, Flatten\n",
        "import cv2 \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfjtqgEnzZ6S",
        "colab_type": "text"
      },
      "source": [
        "This is the MNIST data set used to test the performance on pictures. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpzzgHmOyN_B",
        "colab_type": "code",
        "outputId": "88af0e6f-d0d8-4d71-eb64-4f989ad74a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "num_classes = 10\n",
        "\n",
        "# Configuration\n",
        "img_shape = (256, 256, 3)\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "img_rows, img_cols = 1024, 2048\n",
        "\n",
        "#########################################\n",
        "# Spectrogram \n",
        "x_train = cv2.resize(S_full, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC)\n",
        "x_test = cv2.resize(S_full, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC)\n",
        "x_train = x_train.reshape((1, 2048, 1024, 1))\n",
        "x_test = x_test.reshape((1, 2048, 1024))\n",
        "input_shape = (2048, 1024, 1)\n",
        "\n",
        "#matrix = np.array([[1,1], [0,0]]).astype('float32')\n",
        "#########################################\n",
        "# MNIST \n",
        "# input image dimensions\n",
        "\n",
        "\n",
        "# Process data\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "#x_train = cv2.resize(matrix, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "#x_train = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in S_full])\n",
        "#x_test = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in S_full])\n",
        "\n",
        "\n",
        "#print (input_shape)\n",
        "#if K.image_data_format() == 'channels_first':\n",
        "#    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "#    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "#    input_shape = (1, img_rows, img_cols)\n",
        "#else:\n",
        "#    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "#    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "#    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "#x_train = x_train.astype('float32')\n",
        "#x_test = x_test.astype('float32')\n",
        "#x_train /= 255\n",
        "#x_test /= 255\n",
        "\n",
        "#y_train = to_categorical(y_train, num_classes)\n",
        "#y_test = to_categorical(y_test, num_classes)\n",
        "##########################################\n",
        "'''"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nnum_classes = 10\\n\\n# Configuration\\nimg_shape = (256, 256, 3)\\nbatch_size = 10\\nepochs = 5\\nimg_rows, img_cols = 1024, 2048\\n\\n#########################################\\n# Spectrogram \\nx_train = cv2.resize(S_full, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC)\\nx_test = cv2.resize(S_full, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC)\\nx_train = x_train.reshape((1, 2048, 1024, 1))\\nx_test = x_test.reshape((1, 2048, 1024))\\ninput_shape = (2048, 1024, 1)\\n\\n#matrix = np.array([[1,1], [0,0]]).astype('float32')\\n#########################################\\n# MNIST \\n# input image dimensions\\n\\n\\n# Process data\\n#(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n#x_train = cv2.resize(matrix, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC)\\n\\n#x_train = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in S_full])\\n#x_test = np.array([cv2.resize(x, (img_rows,img_cols), interpolation=cv2.INTER_CUBIC) for x in S_full])\\n\\n\\n#print (input_shape)\\n#if K.image_data_format() == 'channels_first':\\n#    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\\n#    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\\n#    input_shape = (1, img_rows, img_cols)\\n#else:\\n#    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\\n#    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\\n#    input_shape = (img_rows, img_cols, 1)\\n\\n#x_train = x_train.astype('float32')\\n#x_test = x_test.astype('float32')\\n#x_train /= 255\\n#x_test /= 255\\n\\n#y_train = to_categorical(y_train, num_classes)\\n#y_test = to_categorical(y_test, num_classes)\\n##########################################\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ6MuycczWNS",
        "colab_type": "text"
      },
      "source": [
        "This is some random data generate for testing matrices. Not necessary to run. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqcE4dlAyVAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e7914e74-f264-498b-d840-28e0175129a8"
      },
      "source": [
        "'''\n",
        "# Generate data parameters\n",
        "samples = 10\n",
        "channel = 1\n",
        "dim = 32\n",
        "\n",
        "## Random test data \n",
        "train_data = np.array([[[[np.random.randint(low=0, high=10) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)])\n",
        "train_data2 = np.array([[[[np.random.randint(low=0, high=10) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)])\n",
        "test_data = np.array([[[np.random.randint(low=0, high=2)  for y in range(dim)] for z in range(dim)]for n in range(samples)])\n",
        "input_shape = train_data.shape[1:]\n",
        "print (input_shape)\n",
        "'''"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Generate data parameters\\nsamples = 10\\nchannel = 1\\ndim = 32\\n\\n## Random test data \\ntrain_data = np.array([[[[np.random.randint(low=0, high=10) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)])\\ntrain_data2 = np.array([[[[np.random.randint(low=0, high=10) for x in range(channel)] for y in range(dim)] for z in range(dim)]for n in range(samples)])\\ntest_data = np.array([[[np.random.randint(low=0, high=2)  for y in range(dim)] for z in range(dim)]for n in range(samples)])\\ninput_shape = train_data.shape[1:]\\nprint (input_shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr-nYrm8yi1M",
        "colab_type": "text"
      },
      "source": [
        "Define configuration for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrudD_JxyqpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(input_tensor, num_filters):\n",
        "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "  encoder = layers.BatchNormalization()(encoder)\n",
        "  encoder = layers.LeakyReLU(alpha=0.3)(encoder)\n",
        "  return encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "  encoder = conv_block(input_tensor, num_filters)\n",
        "  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\n",
        "  return encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.LeakyReLU(alpha=0.3)(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.LeakyReLU(alpha=0.3)(decoder)\n",
        "  return decoder\n",
        "\n",
        "def output_block(input_tensor, concat_tensor, num_filters):\n",
        "  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.LeakyReLU(alpha=0.3)(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.LeakyReLU(alpha=0.3)(decoder)\n",
        "  \n",
        "  return decoder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahqDIl6_ysKY",
        "colab_type": "text"
      },
      "source": [
        "It is time to put everything together. Call the defined blocks and create the encoder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEsKBMh3iPsU",
        "colab_type": "code",
        "outputId": "aa274d72-3c19-4d2d-e2dd-75797621bd32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "\n",
        "# config normal config: 32, 64, 128, 256, 512 center: 256\n",
        "in1 = 1\n",
        "in2 = 2\n",
        "in3 = 4 \n",
        "\n",
        "print (input_shape)\n",
        "input1 = layers.Input(shape=input_shape, name='input1')\n",
        "input2 = layers.Input(shape=input_shape, name='input2')\n",
        "inputs = [input1, input2]\n",
        "#print (inputs)\n",
        "\n",
        "center = 256\n",
        "##### Network 1 \n",
        "encoder0_pool, encoder0 = encoder_block(input1, in1) # 128\n",
        "encoder1_pool, encoder1 = encoder_block(encoder0_pool, in2) # 64\n",
        "encoder2_pool, encoder2 = encoder_block(encoder1_pool, in3) # 32\n",
        "#encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "#encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "center = conv_block(encoder2_pool, center) # center\n",
        "#decoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "#decoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "decoder2 = decoder_block(center, encoder2, in3) # 64\n",
        "decoder1 = decoder_block(decoder2, encoder1, in2) # 128\n",
        "decoder0 = decoder_block(decoder1, encoder0, in1) # 256\n",
        "output1 = layers.Dense(1, activation='sigmoid')(decoder0)\n",
        "output1 = layers.Reshape((img_cols, img_rows), name='output1')(output1)\n",
        "\n",
        "center2 = 256 \n",
        "##### Network 2\n",
        "encoder_pool, encoder00 = encoder_block(input2, in1) # Input \n",
        "encoder_pool, encoder01 = encoder_block(encoder_pool, in2) #CNN\n",
        "encoder_pool, encoder02 = encoder_block(encoder_pool, in3) #CNN\n",
        "center2 = conv_block(encoder_pool, center2) # CENTER\n",
        "decoder02 = decoder_block(center2, encoder02, in3)\n",
        "decoder01 = decoder_block(decoder02, encoder01, in2)\n",
        "decoder00 = decoder_block(decoder01, encoder00, in1)\n",
        "output2 = layers.Dense(1, activation='sigmoid')(decoder00)\n",
        "output2 = layers.Reshape((img_cols, img_rows), name='output2')(output2)\n",
        " \n",
        "##### Outputs \n",
        "outputs = [output1, output2]\n",
        "\n",
        "model = models.Model(inputs=[inputs], outputs=[outputs])\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 64, 1, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-41828c3921ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m##### Network 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mencoder0_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mencoder1_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder0_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mencoder2_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-ee8488c4726e>\u001b[0m in \u001b[0;36mencoder_block\u001b[0;34m(input_tensor, num_filters)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mencoder_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-ee8488c4726e>\u001b[0m in \u001b[0;36mconv_block\u001b[0;34m(input_tensor, num_filters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 819\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_134 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 1024, 64, 1, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oCnqC-Ny79X",
        "colab_type": "text"
      },
      "source": [
        "Time for training. Compile the model and then call fit to train. Specify which data we want to train on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EvWzs9zHb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss={\n",
        "        'output1': 'mean_squared_error',\n",
        "        'output2': 'mean_squared_error'},\n",
        "    metrics={'output1': 'accuracy',\n",
        "             'output2': 'accuracy'}\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6230FNxRy31V",
        "colab_type": "code",
        "outputId": "d5653675-58a3-4d20-ca0d-5720cb716f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#model.summary()\n",
        "\n",
        "model.fit({'input1': spectoA, 'input2': spectoB}, {'output1': masks1, 'output2': masks2}, epochs=1000)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 656 samples\n",
            "Epoch 1/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2728 - output1_loss: 0.1323 - output2_loss: 0.1406 - output1_acc: 0.0894 - output2_acc: 0.0201\n",
            "Epoch 2/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2638 - output1_loss: 0.1278 - output2_loss: 0.1359 - output1_acc: 0.0994 - output2_acc: 0.0238\n",
            "Epoch 3/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2518 - output1_loss: 0.1232 - output2_loss: 0.1285 - output1_acc: 0.1412 - output2_acc: 0.0480\n",
            "Epoch 4/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2430 - output1_loss: 0.1204 - output2_loss: 0.1227 - output1_acc: 0.1458 - output2_acc: 0.0719\n",
            "Epoch 5/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2350 - output1_loss: 0.1166 - output2_loss: 0.1193 - output1_acc: 0.1560 - output2_acc: 0.0795\n",
            "Epoch 6/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2278 - output1_loss: 0.1130 - output2_loss: 0.1148 - output1_acc: 0.1497 - output2_acc: 0.0767\n",
            "Epoch 7/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2214 - output1_loss: 0.1102 - output2_loss: 0.1115 - output1_acc: 0.1496 - output2_acc: 0.0798\n",
            "Epoch 8/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2150 - output1_loss: 0.1071 - output2_loss: 0.1082 - output1_acc: 0.1445 - output2_acc: 0.0784\n",
            "Epoch 9/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2098 - output1_loss: 0.1045 - output2_loss: 0.1056 - output1_acc: 0.1455 - output2_acc: 0.0830\n",
            "Epoch 10/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2047 - output1_loss: 0.1017 - output2_loss: 0.1026 - output1_acc: 0.1335 - output2_acc: 0.0864\n",
            "Epoch 11/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.2001 - output1_loss: 0.0995 - output2_loss: 0.1006 - output1_acc: 0.1473 - output2_acc: 0.0922\n",
            "Epoch 12/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1957 - output1_loss: 0.0970 - output2_loss: 0.0988 - output1_acc: 0.1207 - output2_acc: 0.0918\n",
            "Epoch 13/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1915 - output1_loss: 0.0946 - output2_loss: 0.0965 - output1_acc: 0.1252 - output2_acc: 0.0954\n",
            "Epoch 14/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1877 - output1_loss: 0.0926 - output2_loss: 0.0946 - output1_acc: 0.1202 - output2_acc: 0.1056\n",
            "Epoch 15/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1844 - output1_loss: 0.0911 - output2_loss: 0.0933 - output1_acc: 0.1338 - output2_acc: 0.1052\n",
            "Epoch 16/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1820 - output1_loss: 0.0902 - output2_loss: 0.0925 - output1_acc: 0.1364 - output2_acc: 0.0995\n",
            "Epoch 17/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1787 - output1_loss: 0.0882 - output2_loss: 0.0903 - output1_acc: 0.1352 - output2_acc: 0.1001\n",
            "Epoch 18/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1763 - output1_loss: 0.0865 - output2_loss: 0.0896 - output1_acc: 0.1361 - output2_acc: 0.0991\n",
            "Epoch 19/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1742 - output1_loss: 0.0856 - output2_loss: 0.0880 - output1_acc: 0.1358 - output2_acc: 0.0910\n",
            "Epoch 20/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1723 - output1_loss: 0.0845 - output2_loss: 0.0873 - output1_acc: 0.1380 - output2_acc: 0.0949\n",
            "Epoch 21/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1709 - output1_loss: 0.0840 - output2_loss: 0.0875 - output1_acc: 0.1462 - output2_acc: 0.0867\n",
            "Epoch 22/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1694 - output1_loss: 0.0829 - output2_loss: 0.0865 - output1_acc: 0.1512 - output2_acc: 0.0869\n",
            "Epoch 23/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1667 - output1_loss: 0.0810 - output2_loss: 0.0853 - output1_acc: 0.1407 - output2_acc: 0.0889\n",
            "Epoch 25/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1660 - output1_loss: 0.0811 - output2_loss: 0.0852 - output1_acc: 0.1435 - output2_acc: 0.0801\n",
            "Epoch 26/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1656 - output1_loss: 0.0810 - output2_loss: 0.0846 - output1_acc: 0.1402 - output2_acc: 0.0844\n",
            "Epoch 27/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1646 - output1_loss: 0.0797 - output2_loss: 0.0849 - output1_acc: 0.1265 - output2_acc: 0.0777\n",
            "Epoch 28/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1646 - output1_loss: 0.0808 - output2_loss: 0.0847 - output1_acc: 0.1305 - output2_acc: 0.0835\n",
            "Epoch 29/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1640 - output1_loss: 0.0790 - output2_loss: 0.0836 - output1_acc: 0.1271 - output2_acc: 0.0795\n",
            "Epoch 30/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1640 - output1_loss: 0.0788 - output2_loss: 0.0848 - output1_acc: 0.1207 - output2_acc: 0.0799\n",
            "Epoch 31/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1635 - output1_loss: 0.0784 - output2_loss: 0.0839 - output1_acc: 0.1233 - output2_acc: 0.0828\n",
            "Epoch 32/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1631 - output1_loss: 0.0796 - output2_loss: 0.0844 - output1_acc: 0.1238 - output2_acc: 0.0833\n",
            "Epoch 33/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1633 - output1_loss: 0.0793 - output2_loss: 0.0841 - output1_acc: 0.1341 - output2_acc: 0.0814\n",
            "Epoch 34/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1629 - output1_loss: 0.0795 - output2_loss: 0.0838 - output1_acc: 0.1381 - output2_acc: 0.0795\n",
            "Epoch 35/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1629 - output1_loss: 0.0794 - output2_loss: 0.0841 - output1_acc: 0.1230 - output2_acc: 0.0813\n",
            "Epoch 36/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1626 - output1_loss: 0.0789 - output2_loss: 0.0852 - output1_acc: 0.1339 - output2_acc: 0.0861\n",
            "Epoch 37/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1627 - output1_loss: 0.0788 - output2_loss: 0.0839 - output1_acc: 0.1175 - output2_acc: 0.0845\n",
            "Epoch 38/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1624 - output1_loss: 0.0781 - output2_loss: 0.0842 - output1_acc: 0.1223 - output2_acc: 0.0865\n",
            "Epoch 39/1000\n",
            "656/656 [==============================] - 2s 3ms/sample - loss: 0.1624 - output1_loss: 0.0784 - output2_loss: 0.0840 - output1_acc: 0.1205 - output2_acc: 0.0853\n",
            "Epoch 40/1000\n",
            " 64/656 [=>............................] - ETA: 1s - loss: 0.1761 - output1_loss: 0.0888 - output2_loss: 0.0872 - output1_acc: 0.1116 - output2_acc: 0.0986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-9168227e4267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspectoA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspectoB\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'output1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmasks1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmasks2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erfugLMM8iwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import utils \n",
        "utils.plot_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
